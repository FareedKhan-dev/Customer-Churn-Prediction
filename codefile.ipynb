{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Members:\n",
    "### Syed Asad Rizvi (ERP ID 25365)\n",
    "### Fareed Hassan Khan (ERP ID 25367)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from numpy import mean\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "from mixed_naive_bayes import MixedNB\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Telecom_customer churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['rev_Mean', 'kid11_15', 'dualband', 'area', 'hnd_price', 'change_mou'], inplace=True)\n",
    "df.drop(['avg6mou', 'avg6qty', 'avg6rev', 'prizm_social_one', 'ownrent', 'lor', 'dwlltype', 'adults', 'infobase', 'numbcars', \n",
    "'HHstatin', 'dwllsize', 'income', 'hnd_webcap'], axis=1, inplace=True)\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onehot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting Model Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, model_name):\n",
    "    model.fit(trainX,trainy)\n",
    "    md_probs = model.predict_proba(testX)\n",
    "    md_probs = md_probs[:,1]\n",
    "    md_auc = roc_auc_score(testy, md_probs)\n",
    "    print(model_name, \" : \", md_auc)\n",
    "    md_fpr, md_tpr, _ = roc_curve(testy, md_probs)\n",
    "    # plt.plot(md_fpr, md_tpr, marker='.', label=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot = df_onehot.loc[:, df_onehot.columns != 'churn']\n",
    "y = df[['churn']]\n",
    "\n",
    "trainX, testX, trainy, testy = train_test_split(df_onehot, y, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(max_depth=5,n_estimators=200)\n",
    "fit_model(gb, \"Graident Boosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lg = Pipeline([(\"scaler\", MinMaxScaler()),(\"Logistic\", LogisticRegression())])\n",
    "fit_model(pipe_lg, \"Logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=5)  \n",
    "fit_model(dt, \"Decision Tree\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=20,n_estimators=1000)\n",
    "fit_model(rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_kn = Pipeline([(\"scaler\", MinMaxScaler()),(\"KNN\", KNeighborsClassifier(n_neighbors=500))])\n",
    "fit_model(pipe_kn, \"KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = list(df.columns[df.dtypes != 'object'])\n",
    "categorical_columns = list(df.columns[df.dtypes == 'object'])\n",
    "categorical_columns.append('churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_categorical(df1):\n",
    "    df_q = pd.DataFrame()\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in df1:\n",
    "        if col not in categorical_columns:\n",
    "            df_q[col] = pd.qcut(df1[col], 5, duplicates='drop')            \n",
    "            df_q[col]= label_encoder.fit_transform(df_q[col])\n",
    "            df_q[col] = df_q[col].astype('str')\n",
    "\n",
    "    X_cat = df1[categorical_columns]\n",
    "    df_cat = pd.concat([df_q,X_cat],axis=1)\n",
    "    return df_cat\n",
    "\n",
    " \n",
    "temp_df1 = convert_categorical(df) \n",
    "temp_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_c = CategoricalNB(min_categories = 100)\n",
    "fit_model(nb_c, \"Naive Bayes Categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_mix = MixedNB(categorical_features=[1,2,3])\n",
    "fit_model(nb_mix, \"Naive Bayes Mixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_g = GaussianNB()\n",
    "fit_model(nb_g, \"Gaussian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "trainX = scaler.fit_transform(trainX)\n",
    "testX = scaler.transform(testX)\n",
    "trainX.shape\n",
    "model = Sequential()\n",
    "model.add(Dense(187, input_dim=187, activation='relu'))\n",
    "model.add(Dense(187, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(trainX, trainy, epochs=5, batch_size=10)\n",
    "_, accuracy = model.evaluate(testX, testy)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedKFold(n_splits=10, n_repeats=1)#, random_state=1)\n",
    "reg_bg = BaggingClassifier(base_estimator=GradientBoostingClassifier(max_depth=5, n_estimators=200),\n",
    "                        n_estimators=20, random_state=0)\n",
    "scores = cross_val_score(reg_bg, df_onehot, y, cv=cv)\n",
    "score = format(mean(scores), '.4f')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=1)#, random_state=1)\n",
    "estimators = [\n",
    "('lr', LogisticRegression()),\n",
    "('dt', DecisionTreeClassifier(max_depth=5)),\n",
    "('rf', RandomForestClassifier(max_depth=20, n_estimators=1000))\n",
    "]\n",
    "\n",
    "reg_sr = StackingClassifier(estimators=estimators, final_estimator=GradientBoostingClassifier(max_depth=5, n_estimators=200, random_state=42))\n",
    "scores = cross_val_score(reg_sr, df_onehot, y, cv=cv)\n",
    "score = format(mean(scores), '.4f')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedKFold(n_splits=10, n_repeats=1)#, random_state=1)\n",
    "r1 = DecisionTreeClassifier(max_depth=5)\n",
    "r2 = RandomForestClassifier(max_depth=20,n_estimators=1000)\n",
    "r3 = GradientBoostingClassifier(max_depth=5,n_estimators=200)\n",
    "\n",
    "reg_vr = VotingClassifier([('dt', r1), ('rf', r2),('gb', r3)])\n",
    "scores = cross_val_score(reg_vr, df_onehot, y, cv=cv)\n",
    "score = format(mean(scores), '.4f')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Float values\n",
    "x = df['avg6mou'].mode()\n",
    "df['avg6mou'].fillna(x[0], inplace=True)\n",
    "y = df['avg6qty'].mode()\n",
    "df['avg6qty'].fillna(y[0], inplace=True)\n",
    "z = df['avg6rev'].mode()\n",
    "df['avg6rev'].fillna(z[0], inplace=True)\n",
    "a = df['lor'].mode()\n",
    "df['lor'].fillna(a[0], inplace=True)\n",
    "b = df['adults'].mode()\n",
    "df['adults'].fillna(b[0], inplace=True)\n",
    "c = df['income'].mode()\n",
    "df['income'].fillna(c[0], inplace=True)\n",
    "d = df['numbcars'].mode()\n",
    "df['numbcars'].fillna(d[0], inplace=True)\n",
    "\n",
    "# Categorical\n",
    "e = df['prizm_social_one'].mode()\n",
    "df['prizm_social_one'].fillna(e[0], inplace=True)\n",
    "f = df['hnd_webcap'].mode()\n",
    "df['hnd_webcap'].fillna(f[0], inplace=True)\n",
    "g = df['ownrent'].mode()\n",
    "df['ownrent'].fillna(g[0], inplace=True)\n",
    "h = df['infobase'].mode()\n",
    "df['infobase'].fillna(h[0], inplace=True)\n",
    "i = df['HHstatin'].mode()\n",
    "df['HHstatin'].fillna(i[0], inplace=True)\n",
    "j = df['dwllsize'].mode()\n",
    "df['dwllsize'].fillna(j[0], inplace=True)\n",
    "k = df['dwlltype'].mode()\n",
    "df['dwlltype'].fillna(j[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_onehot.loc[:, df_onehot.columns != 'churn']\n",
    "y = df_onehot[['churn']]\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "regRF = GradientBoostingClassifier(max_depth=5, random_state=0)\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'max_features': [2, 3, 4],    \n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300] \n",
    "}\n",
    "grid_search = GridSearchCV(estimator = regRF, param_grid=param_grid, cv = cv, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(X, y)\n",
    "best_grid = grid_search.best_estimator_\n",
    "print(best_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_onehot = []\n",
    "s_no = []\n",
    "for i in range(0,10):\n",
    "    # prepare the cross-validation procedure\n",
    "    cv = KFold(n_splits=10, random_state=i, shuffle=True)\n",
    "    reg = LogisticRegression()\n",
    "    \n",
    "\n",
    "    scores = cross_val_score(reg, df_onehot, y, scoring='roc_auc', cv=cv) \n",
    "    score_onehot.append(mean(scores))\n",
    "    \n",
    "    s_no.append(i)\n",
    "    \n",
    "scores_df = pd.DataFrame(\n",
    "    {'S #': s_no,\n",
    "     'onehot': score_onehot\n",
    "    })\n",
    "scores_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_onehot.loc[:, df_onehot.columns != 'churn']\n",
    "y = df_onehot[['churn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(max_depth=5, n_estimators=200, random_state=0)\n",
    "\n",
    "clf.fit(X,y)\n",
    "\n",
    "feature_scores = pd.Series(clf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "feature_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winner Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(max_depth=5,n_estimators=200)\n",
    "fit_model(gb, \"Graident Boosting\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54ce3980bf0da3a4aa77af90eb2458675cc73ddb313d5ac3f2fab994261f3811"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
